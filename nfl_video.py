# -*- coding: utf-8 -*-
"""NFL - Video.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fxAj6wbdPRB7g-7B42QhnHbPq7NpC0Hc

# Feito por: Johannes Sesselmann
### Análise de Dados de jogadores de Futebol Americano da NFL
"""

# general
import numpy as np
import pandas as pd

# IA
from sklearn.metrics import matthews_corrcoef

# matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.animation as animation

"""---
<p style="background-color:white">Primeiramente precisamos extraídos os dados já fornecidos pela competição:
"""

# Labels e sample submission

labels = pd.read_csv(r'/content/drive/MyDrive/NFL/train_labels.csv', parse_dates=["datetime"])

ss = pd.read_csv(r'/content/drive/MyDrive/NFL/sample_submission.csv')

# Player tracking data

tr_tracking = pd.read_csv(
    r"/content/drive/MyDrive/NFL/train_player_tracking.csv", parse_dates=["datetime"]
)
te_tracking = pd.read_csv(
    r"/content/drive/MyDrive/NFL/test_player_tracking.csv", parse_dates=["datetime"]
)

# Baseline helmet detection labels

tr_helmets = pd.read_csv(r"/content/drive/MyDrive/NFL/train_baseline_helmets.csv")
te_helmets = pd.read_csv(r"/content/drive/MyDrive/NFL/test_baseline_helmets.csv")

# Video metadata com start/stop timestamps

tr_video_metadata = pd.read_csv(
    "/content/drive/MyDrive/NFL/train_video_metadata.csv",
    parse_dates=["start_time", "end_time", "snap_time"],
)

"""

---
A competição já facilita 90% do trabalho ao mostrar a lógica de criação de uma 'caixa' para cada jogador. Mais tarde veremos como ela fica!
"""

import os
import cv2
import subprocess

def video_with_helmets(
    video_path: str, baseline_boxes: pd.DataFrame, verbose=True
) -> str:
    """
    Anota um vídeo com caixas e número do jogador
    """
    VIDEO_CODEC = "MP4V"
    HELMET_COLOR = (0, 0, 0)  # preto
    video_name = os.path.basename(video_path)
    if verbose:
        print(f"Running for {video_name}")
    baseline_boxes = baseline_boxes.copy()

    vidcap = cv2.VideoCapture(video_path)
    fps = vidcap.get(cv2.CAP_PROP_FPS)
    width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    output_path = "labeled_" + video_name
    tmp_output_path = "tmp_" + output_path
    output_video = cv2.VideoWriter(
        tmp_output_path, cv2.VideoWriter_fourcc(*VIDEO_CODEC), fps, (width, height)
    )

    frame = 0
    while True:
        it_worked, img = vidcap.read()
        if not it_worked:
            break
        # Início da contagem do frame
        frame += 1

        # Colocar o frame no topo do video
        img_name = video_name.replace(".mp4", "")
        cv2.putText(
            img,
            img_name,
                        (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            HELMET_COLOR,
            thickness=1,
        )

        cv2.putText(
            img,
            str(frame),
            (1280 - 90, 720 - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            HELMET_COLOR,
            thickness=1,
        )
        # Criação das caixas para cada jogador
        boxes = baseline_boxes.query("video == @video_name and frame == @frame")
        for box in boxes.itertuples(index=False):
            cv2.rectangle(
                img,
                (box.left, box.top),
                (box.left + box.width, box.top + box.height),
                HELMET_COLOR,
                thickness=1,
            )
            cv2.putText(
                img,
                box.player_label,
                (box.left + 1, max(0, box.top - 20)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                HELMET_COLOR,
                thickness=1,
            )

        output_video.write(img)
    output_video.release()
    # Precaução se der erro:
    # Not all browsers support the codec, we will re-load the file at tmp_output_path
    # and convert to a codec that is more broadly readable using ffmpeg
    if os.path.exists(output_path):
        os.remove(output_path)
    subprocess.run(
        [
            "ffmpeg",
            "-i",
            tmp_output_path,
            "-crf",
            "18",
            "-preset",
            "veryfast",
            "-hide_banner",
            "-loglevel",
            "error",
            "-vcodec",
            "libx264",
            output_path,
        ]
    )
    os.remove(tmp_output_path)

    return output_path

"""

---
Criação de um label para cada jogador e inserir ele no vídeo. Note que o label precisa acompanhar o jogador."""

def annotate_video_with_helmets(video_path: str, baseline_boxes:pd.DataFrame, verbose=True) -> str:
    """
    Annotates a video with baseline model boxes and labels.
    """
    video_name = video_path.split('/')[-1]
    play_name = video_name.split('.')[0]
    HELMET_COLOR = (0, 0, 0) # preto
    baseline_boxes = baseline_boxes.query("video==@video_name").copy()
    
    # verbose (função acima)
    if verbose==True:
        print(f"Running for {video_name}")
    
    # Captura de vídeo
    cap  = cv2.VideoCapture(video_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    # Escrever no vídeo
    output_path = "labeled_" + video_name
    tmp_output_path = "tmp_" + output_path
    out = cv2.VideoWriter(tmp_output_path, cv2.VideoWriter_fourcc(*'MP4V'), 
                          fps, (width, height))
    
    # checar se arquivo mp4 abre corretamente
    if cap.isOpened() == False:
        print('Erro ao abrir o arquivo!')
        
    # ver todos os frames
    frame  = 1
    while(cap.isOpened()):
        # capturar frame um por um
        ret, img = cap.read()
        
        if ret==True:
            # adicionar play_name text
            cv2.putText(img, play_name,
                       (int(0.01*width), int(0.05*height)),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1,
                        HELMET_COLOR,
                        1
                       )
            
            # adicionar contador de frame
            cv2.putText(img, "Frame: "+str(frame),
                       (int(0.75*width), int(0.05*height)),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1,
                        HELMET_COLOR,
                        1
                       )

            # a caixa do jogador vai ficar verde se ele encostar em alguem
            bbox_set = baseline_boxes.query("frame==@frame")
            for i, annot in enumerate(zip(np.array(bbox_set[['player_label','left','width','top','height']]))):
                player_label, bbox_left, bbox_width, bbox_top, bbox_height = annot[0]
                # adicionar caixa
                cv2.rectangle(img, 
                              (bbox_left,bbox_top), (bbox_left+bbox_width, bbox_top+bbox_height),
                              HELMET_COLOR,
                              1
                             )
                # adicionar label do jogador
                cv2.putText(img, player_label,
                       (bbox_left+10, bbox_top+10),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1,
                        HELMET_COLOR,
                        1
                       )
            
            frame += 1
            out.write(img) 
                 
        else: 
            break
        
        
    out.release()
    
    # Not all browsers support the codec, we will re-load the file at tmp_output_path
    # and convert to a codec that is more broadly readable using ffmpeg
    if os.path.exists(output_path):
        os.remove(output_path)
    subprocess.run(
        [
            "ffmpeg",
            "-i",
            tmp_output_path,
            "-crf",
            "18",
            "-preset",
            "veryfast",
            "-hide_banner",
            "-loglevel",
            "error",
            "-vcodec",
            "libx264",
            output_path,
        ]
    )
    os.remove(tmp_output_path)
    
    return output_path

def play_video(video_path: str):
    frac = 0.65 # scaling factor for display 
    display(
        Video(data=video_path, embed=True, height=int(720*frac), width=int(1280*frac))
    )

"""

---
Vamos escolher um mp4 arbitrariamente do dataset e ver como ele foi gravado:
"""

video_path = "/content/drive/MyDrive/NFL/train/58168_003392_Endzone.mp4"
play_video(video_path)

"""

---
Agora vamos ver como fica o mesmo vídeo com as caixas criadas anteriormente:
"""

path = annotate_video_with_helmets(video_path, tr_helmets)
play_video(path)

"""

---
E se mudarmos o ângulo da câmera? Será que dá certo?"""

example_video = "/content/drive/MyDrive/NFL/train/58168_003392_Sideline.mp4"
output_video = annotate_video_with_helmets(example_video, tr_helmets)

frac = 0.65  # scaling factor for display
display(
    Video(data=output_video, embed=True, height=int(720 * frac), width=int(1280 * frac))
)  #não sei o motivo mas a função play_video parou de funcionar! tive q copiar novamente

"""

---
Agora é a hora que a gente complica o problema, e se criamos uma função - contato para cada jogador? Nesse caso, quando um jogador encostar em outro a caixinha vai ficar verde e criar um laço azul para mostrar a distancia entre eles após o contato.
"""

def join_helmets_contact(game_play, labels, helmets, meta, view="Sideline", fps=59.94):
  
    gp_labs = labels.query("game_play == @game_play").copy()
    gp_helms = helmets.query("game_play == @game_play").copy()

    start_time = meta.query("game_play == @game_play and view == @view")[
        "start_time"
    ].values[0]

    gp_helms["datetime"] = (
        pd.to_timedelta(gp_helms["frame"] * (1 / fps), unit="s") + start_time
    )
    gp_helms["datetime"] = pd.to_datetime(gp_helms["datetime"], utc=True)
    gp_helms["datetime_ngs"] = (
        pd.DatetimeIndex(gp_helms["datetime"] + pd.to_timedelta(50, "ms"))
        .floor("100ms")
        .values
    )
    gp_helms["datetime_ngs"] = pd.to_datetime(gp_helms["datetime_ngs"], utc=True)

    gp_labs["datetime_ngs"] = pd.to_datetime(gp_labs["datetime"], utc=True)

    gp = gp_helms.merge(
        gp_labs.query("contact == 1")[
            ["datetime_ngs", "nfl_player_id_1", "nfl_player_id_2", "contact_id"]
        ],
        left_on=["datetime_ngs", "nfl_player_id"],
        right_on=["datetime_ngs", "nfl_player_id_1"],
        how="left",
    )
    return gp

"""

---
O que eu vou fazer agora é uma coisa meio feia, mas vou pegar a função que já tinha criado anteriormente e modificar ela ao meu gosto. O resultado vai ficar bonito eu prometo!
"""

import os
import cv2
import subprocess
from IPython.display import Video, display
import pandas as pd


def video_with_contact(
    video_path: str, baseline_boxes: pd.DataFrame, verbose=True
) -> str:
    """
    Essa função faz a mesma coisa que a anterior, só que dessa vez com cores.
    """
    VIDEO_CODEC = "MP4V"
    HELMET_COLOR = (0, 0, 0)  # preto
    video_name = os.path.basename(video_path)
    if verbose:
        print(f"Running for {video_name}")
    baseline_boxes = baseline_boxes.copy()

    vidcap = cv2.VideoCapture(video_path)
    fps = vidcap.get(cv2.CAP_PROP_FPS)
    width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    output_path = "contact_" + video_name
    tmp_output_path = "tmp_" + output_path
    output_video = cv2.VideoWriter(
        tmp_output_path, cv2.VideoWriter_fourcc(*VIDEO_CODEC), fps, (width, height)
    )
    frame = 0
    while True:
        it_worked, img = vidcap.read()
        if not it_worked:
            break

        #Começar os frames
        frame += 1

        # Criar um index de frame pra sabermos onde estamos no vídeo
        img_name = video_name.replace('.mp4','')
        cv2.putText(
            img,
            img_name,
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            HELMET_COLOR,
            thickness=1,
        )
        
        cv2.putText(
            img,
            str(frame),
            (1280 - 90, 720 - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            HELMET_COLOR,
            thickness=1,
        )

        # Adicionar as caixas de cada jogador
        boxes = baseline_boxes.query("video == @video_name and frame == @frame")
        contact_players = boxes.dropna(subset=["nfl_player_id_2"]).query(
            'nfl_player_id_2 != "G"'
        )
        contact_ids = (
            contact_players["nfl_player_id_1"].astype("int").values.tolist()
            + contact_players["nfl_player_id_2"].astype("int").values.tolist()
        )
        for box in boxes.itertuples(index=False):
            #Blue - Green - Red
            if box.nfl_player_id_2 == "G":
                box_color = (0, 0, 255)  # Essa cor é vermelha
                box_thickness = 2
            elif int(box.nfl_player_id) in contact_ids:
                box_color = (0, 255, 0)  # Essa cor é verde
                box_thickness = 2

                # Adicionar linha entre jogadores em contato
                if not np.isnan(float(box.nfl_player_id_2)):
                    player2 = int(box.nfl_player_id_2)
                    player2_row = boxes.query("nfl_player_id == @player2")
                    if len(player2_row) == 0:
                        continue
                    cv2.line(
                        img,
                        (box.left + int(box.width / 2), box.top + int(box.height / 2)),
                        (
                            player2_row.left.values[0]
                            + int(player2_row.width.values[0] / 2),
                            player2_row.top.values[0]
                            + int(player2_row.height.values[0] / 2),
                        ),
                        color=(255, 0, 0),
                        thickness=2,
                    )

            else:
                box_color = HELMET_COLOR
                box_thickness = 1

            # Desenho das linhas azuis

            cv2.rectangle(
                img,
                (box.left, box.top),
                (box.left + box.width, box.top + box.height),
                box_color,
                thickness=box_thickness,
            )
            cv2.putText(
                img,
                box.player_label,
                (box.left + 1, max(0, box.top - 20)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                HELMET_COLOR,
                thickness=1,
            )

        output_video.write(img)
    output_video.release()

    # Precaução se der erro:
    # Not all browsers support the codec, we will re-load the file at tmp_output_path
    # and convert to a codec that is more broadly readable using ffmpeg
    if os.path.exists(output_path):
        os.remove(output_path)
    subprocess.run(
        [
            "ffmpeg",
            "-i",
            tmp_output_path,
            "-crf",
            "18",
            "-preset",
            "veryfast",
            "-hide_banner",
            "-loglevel",
            "error",
            "-vcodec",
            "libx264",
            output_path,
        ]
    )
    os.remove(tmp_output_path)

    return output_path

game_play = "58168_003392"
gp = join_helmets_contact(game_play, labels, tr_helmets, tr_video_metadata)

example_video = "/content/drive/MyDrive/NFL/train/58168_003392_Endzone.mp4"
output_video = video_with_contact(example_video, gp)

frac = 0.65  # tamanho do display
display(
    Video(data=output_video, embed=True, height=int(720 * frac), width=int(1280 * frac))
)

"""

---
Próximos passos:


*   Otimizar o tamanho e processamento dos vídeos (descobri algumas formas que dá pra fazer) --> meu laptop quase explodiu rodando esse programa.
*   Criar uma função que identifica a bola e acompanha ela.
*   Após criar a função que identifica a bola --> fazer uma análise se o jogador fez uma boa jogada ou não.


"""